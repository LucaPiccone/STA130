# 1


import pandas as pd

url = "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv"
df = pd.read_csv(url)

df.isnull().sum()


# 2 


# Get the number of rows and columns
rows, columns = df.shape

f"The DataFrame has {rows} rows and {columns} columns."


"""
# Every observation refers to a single row in a dataset, 
# they consists of data values for a number of variables. 
# Observations are records that are gathered and recoreded 
# for data purposes. 

# Variables correspond to columns in the dataset and 
# represent the traits or qualities measured 
# or noted on an observation. Variables can be classified 
# into quantitative (numeric) or qualitative (non-numerci) 
# categories.
"""


# 3


# Summary of numerical columns. (Notice how age is missing columns and it is reflected in the count)
df.describe()


# Return the count of each unique values in a non-numeric column.
df['embark_town'].value_counts()


# Loop through all the columns, 
# print the counts for each columns unique values.
for column in df.columns:
    print(f"Value counts for column '{column}':")
    print(df[column].value_counts())
    print("\n" + "="*50 + "\n")  # Separator for better readability


# 4


"""
df.shape() is used to return the total number of rows
and columns regardless if they're numeric, non-numeric 
or missing values. It returns a tuple with the format 
(number_of_rows, number_of_columns)

df.describe() provides summary statistics for numerical 
columns, ignoring missing values (NaN) and displaying the count 
for non-missing values.

As a result, the 'count' in df.describe() may differ from
the 'count' shown in df.shape(), since missing values in 
numeric columns cause the 'count' to be less than the total
row count respectively.
"""


# 5


"""
An "attribute", such as df.shape, which does not end with (), 
are variable that are associated with an object or class. It 
represents the state or properties of that object and can be
provided to the user without doing any extra work or calculations.

Methods, such as df.describe(), which end with (), is a block of 
code that performs actions or operations on an object. Methods 
are similar to functions, but they are associated with an object. 
When a method is called, the object it is invoked on is 
automatically passed as an argument to the method, and you can 
also include additional arguments within the parentheses.
"""


# 6


"""
Description of the statistics provided by df.describe().

count: Displays the count of non-missing observations 
in the column.

mean: adding up all the data values and dividing the 
sum by the total number of values.

std Deviation: A measure of spread, and is related 
to the mean as the measure of central tendency. 
The mean gives us the middle value and then the 
variance and standard deviation is calculated. 
A higher standard deviation means more spread out 
values.

min: The smallest value in the column represents the 
lowest observed data points. 

25%: Also known as the first quartile, is a measure 
that indicates the value below which 25% of the data 
points fall. 

50%: Also known as the median, it is the value in the 
middle of the data, when the data values are sorted 
from smallest to largest. It divides the data into two 
equal halves, where 50% of the data points are below and
50% are above. 

75%: The third quartile, it is the data value which is
greater than 75% of the data values. It provides insight 
into the higher end of the data distribution. 

max: The largest observed data value in that column. 
"""


# 7


"""
df.dropna() removes rows that contain at least one 
missing value. 

df.dropna(subset=['col1', 'col2']) to remove rows 
with missing values in specific columns.

del df['col'] Deletes an entire column from the 
DataFrame. Used when you determine a column is 
not useful for analysis because it has to many 
missing values or is irrelevant. 

#  1  

    Consider a dataset where each observation is a
review on a particular item and one column contains
ratings. If a few ratings are missing, using df.dropna()
to remove the rows with missing ratings rather than 
removing the whole column is preferred because the 
rating column is important to understanding customer
feedback. Retaining the column and focusing on complete
rows will provide more accurate and meaningful 
reviews, even if it means working with less data.

#  2

    Consider a dataset for customer reviews with a column
for reviewer_age. If the reviewer_age column has a large 
number of missing values and it is not critical for understanding
customer feedback, using del col['reviewer_age'] might be 
preferred over df.dropna(). Removing this column simplifies
the dataset and focuses your analysis on other columns like
ratings.

#  3 

    It is important to remove a column with a substantial 
amount of missing values before using df.dropna() because
if not first removed, the method will remove a large 
number of rows containing valuable data. By deleting a 
problematic column first, you ensure that df.dropna()
only affects the remaining columns, thus preserving more
relevant data and improving the efficiency of the data 
cleaning process. 

#  4 

    To remove all missing data from a dataset appropriately 
first, use df.isnull().sum to check all the columns for 
missing data. If a column has a substantial amount of 
missing data, remove that column using del df['col']. 
Then, decide whether you should use df.dropna() to remove 
the observations that countain missing data. However, before 
deleteing a column debate the importance of that column
to your analysis. 

"""



df_copy = df.copy()

del df_copy['deck']

del df_copy['age']

df_copy.dropna(inplace=True)

print("Missing values count")
print(df_copy.isnull().sum())

rows_copy, columns_copy = df_copy.shape

f"The DataFrame has {rows} rows and {columns} columns."



# 8 


# Make sure we are working with the original data 
print("Missing values count")
print(df.isnull().sum())

rows_copy, columns_copy = df.shape

f"The DataFrame has {rows} rows and {columns} columns."


#  8. (1)
# Group the data into the unique values found in column 'who'
# Which happen to be 'man', 'woman' and 'child.
# Do summary analysis on every individual group. 

# Return grouped summary analysis of 'fare' based on the 
# unique groups of column 'who'.
df.groupby("who")["fare"].describe()


# 8. (2)

df.describe()

# Note that 83.0 + 537.0 + 271.0 = 891.0 

"""
The count returned by df.groupby("who")["fare"].describe()
represents the number of non-missing values returned for 
each unique group in the column "who". Whereas the count 
returned by df.describe() provides you the number of 
non-missing values in each column across the DataFrame.
"""


#  8. (3)

import pandas as pd
url = "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv"
df = pd.read_csv(url)

# a)
# The Chat bot instantly told me to import pandas as pd.
# After copying and pasting the same error into google
# the first was result I clicked was a stackoverflow 
# website that told me to install seaborn. 

# b)
# The chatbot knew there was an issue with the path and
# provided the right path, possibly because of our 
# previous chat. The first google result is a stackoverflow
# site which mentions using a direct path, but can not 
# provide me the exactly url to the file. 

# c)
# Chatgpt tells me that DF has not been defined or assigned a
# DataFrame in my code and provides the code to fix it. 
# Google tells me to make sure my DataFrame is declared 
# before access. 

# d)
# Chatbot tells me that I am likely missing a closing parenthesis.
# Google told me to make sure the code lines up with the proper 
# indentation level. 

# e)
# Chatgpt instantly told me the code I needed to use. 
# The first google result told me the correct function name.
# https://www.reddit.com/r/learnpython/comments/80rrvr/pandas_attributeerror_dataframe_object_has_no/
# Google search: AttributeError: 'DataFrame' object has no attribute 'group_by'

# f)
# Chatbot told me that the column doesn't exist, provided 
# me the code to check the columns in the DataFrame and 
# also provided me the code I was looking for. 
# It took a long time to find the problem using Gooogle. 

# g) Chatbot mention there was an error in my code with the 
# column name fare and provided me the code to fix it. 
# Google didn't find the exact problem. But It found similar problems.
# Using google would have taken me alot more longer to solve. 
                 




# df.groupby("Who")[fare].describe()


# 9 
# Yes




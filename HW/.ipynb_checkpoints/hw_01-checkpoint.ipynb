{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8002533-e2cb-41fe-83f2-a9251a561601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bab25bbf-1ae2-4500-b7f3-0093381de4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31e278-6af8-4c86-a991-2207ddc4a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2ec22a07-375e-4403-8801-56908cf68576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The DataFrame has 891 rows and 15 columns.'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of rows and columns\n",
    "rows, columns = df.shape\n",
    "\n",
    "f\"The DataFrame has {rows} rows and {columns} columns.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0e774-fe6b-4f44-ac0a-cc3506ac3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Every observation refers to a single row in a dataset, \n",
    "# they consists of data values for a number of variables. \n",
    "# Observations are records that are gathered and recoreded \n",
    "# for data purposes. \n",
    "\n",
    "# Variables correspond to columns in the dataset and \n",
    "# represent the traits or qualities measured \n",
    "# or noted on an observation. Variables can be classified \n",
    "# into quantitative (numeric) or qualitative (non-numerci) \n",
    "# categories.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97ab3a-ac06-4655-9903-f9da2f20f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5602f40-ae09-479a-a9eb-9238f55ca2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of numerical columns. (Notice how age is missing columns and it is reflected in the count)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72f1a321-4c85-4738-a4cd-74183b2c1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embark_town\n",
       "Southampton    644\n",
       "Cherbourg      168\n",
       "Queenstown      77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the count of each unique values in a non-numeric column.\n",
    "df['embark_town'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4637aa40-e03b-401b-acc2-ca8b63df0f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column 'survived':\n",
      "survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'pclass':\n",
      "pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'sex':\n",
      "sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'age':\n",
      "age\n",
      "24.00    30\n",
      "22.00    27\n",
      "18.00    26\n",
      "19.00    25\n",
      "28.00    25\n",
      "         ..\n",
      "36.50     1\n",
      "55.50     1\n",
      "0.92      1\n",
      "23.50     1\n",
      "74.00     1\n",
      "Name: count, Length: 88, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'sibsp':\n",
      "sibsp\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'parch':\n",
      "parch\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'fare':\n",
      "fare\n",
      "8.0500     43\n",
      "13.0000    42\n",
      "7.8958     38\n",
      "7.7500     34\n",
      "26.0000    31\n",
      "           ..\n",
      "35.0000     1\n",
      "28.5000     1\n",
      "6.2375      1\n",
      "14.0000     1\n",
      "10.5167     1\n",
      "Name: count, Length: 248, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'embarked':\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'class':\n",
      "class\n",
      "Third     491\n",
      "First     216\n",
      "Second    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'who':\n",
      "who\n",
      "man      537\n",
      "woman    271\n",
      "child     83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'adult_male':\n",
      "adult_male\n",
      "True     537\n",
      "False    354\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'deck':\n",
      "deck\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'embark_town':\n",
      "embark_town\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'alive':\n",
      "alive\n",
      "no     549\n",
      "yes    342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Value counts for column 'alone':\n",
      "alone\n",
      "True     537\n",
      "False    354\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the columns, \n",
    "# print the counts for each columns unique values.\n",
    "for column in df.columns:\n",
    "    print(f\"Value counts for column '{column}':\")\n",
    "    print(df[column].value_counts())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c38733-de06-4d7b-981c-21e38bf4f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c7626-e3c7-44b4-a7de-739da39c154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df.shape() is used to return the total number of rows\n",
    "and columns regardless if they're numeric, non-numeric \n",
    "or missing values. It returns a tuple with the format \n",
    "(number_of_rows, number_of_columns)\n",
    "\n",
    "df.describe() provides summary statistics for numerical \n",
    "columns, ignoring missing values (NaN) and displaying the count \n",
    "for non-missing values.\n",
    "\n",
    "As a result, the 'count' in df.describe() may differ from\n",
    "the 'count' shown in df.shape(), since missing values in \n",
    "numeric columns cause the 'count' to be less than the total\n",
    "row count respectively.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8c1e1-ec52-45e7-8a36-c3936fde41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b8361-53bb-4b0d-91d3-f09579730813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An \"attribute\", such as df.shape, which does not end with (), \n",
    "are variable that are associated with an object or class. It \n",
    "represents the state or properties of that object and can be\n",
    "provided to the user without doing any extra work or calculations.\n",
    "\n",
    "Methods, such as df.describe(), which end with (), is a block of \n",
    "code that performs actions or operations on an object. Methods \n",
    "are similar to functions, but they are associated with an object. \n",
    "When a method is called, the object it is invoked on is \n",
    "automatically passed as an argument to the method, and you can \n",
    "also include additional arguments within the parentheses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8498d-82fe-44fd-b1ab-3103928831e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24fe6d-a185-4c6d-90f1-2ac729258f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description of the statistics provided by df.describe().\n",
    "\n",
    "count: Displays the count of non-missing observations \n",
    "in the column.\n",
    "\n",
    "mean: adding up all the data values and dividing the \n",
    "sum by the total number of values.\n",
    "\n",
    "std Deviation: A measure of spread, and is related \n",
    "to the mean as the measure of central tendency. \n",
    "The mean gives us the middle value and then the \n",
    "variance and standard deviation is calculated. \n",
    "A higher standard deviation means more spread out \n",
    "values.\n",
    "\n",
    "min: The smallest value in the column represents the \n",
    "lowest observed data points. \n",
    "\n",
    "25%: Also known as the first quartile, is a measure \n",
    "that indicates the value below which 25% of the data \n",
    "points fall. \n",
    "\n",
    "50%: Also known as the median, it is the value in the \n",
    "middle of the data, when the data values are sorted \n",
    "from smallest to largest. It divides the data into two \n",
    "equal halves, where 50% of the data points are below and\n",
    "50% are above. \n",
    "\n",
    "75%: The third quartile, it is the data value which is\n",
    "greater than 75% of the data values. It provides insight \n",
    "into the higher end of the data distribution. \n",
    "\n",
    "max: The largest observed data value in that column. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64206c1-fbc8-4d2f-b6aa-a9e76fa560b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "257aa7ea-4749-48de-b3e6-d7dd7afdd590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf.dropna() removes rows that contain at least one \\nmissing value. \\n\\ndf.dropna(subset=['col1', 'col2']) to remove rows \\nwith missing values in specific columns.\\n\\ndel df['col'] Deletes an entire column from the \\nDataFrame. Used when you determine a column is \\nnot useful for analysis because it has to many \\nmissing values or is irrelevant. \\n\\n#  1  \\n\\n    Consider a dataset where each observation is a\\nreview on a particular item and one column contains\\nratings. If a few ratings are missing, using df.dropna()\\nto remove the rows with missing ratings rather than \\nremoving the whole column is preferred because the \\nrating column is important to understanding customer\\nfeedback. Retaining the column and focusing on complete\\nrows will provide more accurate and meaningful \\nreviews, even if it means working with less data.\\n\\n#  2\\n\\n    Consider a dataset for customer reviews with a column\\nfor reviewer_age. If the reviewer_age column has a large \\nnumber of missing values and it is not critical for understanding\\ncustomer feedback, using del col['reviewer_age'] might be \\npreferred over df.dropna(). Removing this column simplifies\\nthe dataset and focuses your analysis on other columns like\\nratings.\\n\\n#  3 \\n\\n    It is important to remove a column with a substantial \\namount of missing values before using df.dropna() because\\nif not first removed, the method will remove a large \\nnumber of rows containing valuable data. By deleting a \\nproblematic column first, you ensure that df.dropna()\\nonly affects the remaining columns, thus preserving more\\nrelevant data and improving the efficiency of the data \\ncleaning process. \\n\\n#  4 \\n\\n    To remove all missing data from a dataset appropriately \\nfirst, use df.isnull().sum to check all the columns for \\nmissing data. If a column has a substantial amount of \\nmissing data, remove that column using del df['col']. \\nThen, decide whether you should use df.dropna() to remove \\nthe observations that countain missing data. However, before \\ndeleteing a column debate the importance of that column\\nto your analysis. \\n\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df.dropna() removes rows that contain at least one \n",
    "missing value. \n",
    "\n",
    "df.dropna(subset=['col1', 'col2']) to remove rows \n",
    "with missing values in specific columns.\n",
    "\n",
    "del df['col'] Deletes an entire column from the \n",
    "DataFrame. Used when you determine a column is \n",
    "not useful for analysis because it has to many \n",
    "missing values or is irrelevant. \n",
    "\n",
    "#  1  \n",
    "\n",
    "    Consider a dataset where each observation is a\n",
    "review on a particular item and one column contains\n",
    "ratings. If a few ratings are missing, using df.dropna()\n",
    "to remove the rows with missing ratings rather than \n",
    "removing the whole column is preferred because the \n",
    "rating column is important to understanding customer\n",
    "feedback. Retaining the column and focusing on complete\n",
    "rows will provide more accurate and meaningful \n",
    "reviews, even if it means working with less data.\n",
    "\n",
    "#  2\n",
    "\n",
    "    Consider a dataset for customer reviews with a column\n",
    "for reviewer_age. If the reviewer_age column has a large \n",
    "number of missing values and it is not critical for understanding\n",
    "customer feedback, using del col['reviewer_age'] might be \n",
    "preferred over df.dropna(). Removing this column simplifies\n",
    "the dataset and focuses your analysis on other columns like\n",
    "ratings.\n",
    "\n",
    "#  3 \n",
    "\n",
    "    It is important to remove a column with a substantial \n",
    "amount of missing values before using df.dropna() because\n",
    "if not first removed, the method will remove a large \n",
    "number of rows containing valuable data. By deleting a \n",
    "problematic column first, you ensure that df.dropna()\n",
    "only affects the remaining columns, thus preserving more\n",
    "relevant data and improving the efficiency of the data \n",
    "cleaning process. \n",
    "\n",
    "#  4 \n",
    "\n",
    "    To remove all missing data from a dataset appropriately \n",
    "first, use df.isnull().sum to check all the columns for \n",
    "missing data. If a column has a substantial amount of \n",
    "missing data, remove that column using del df['col']. \n",
    "Then, decide whether you should use df.dropna() to remove \n",
    "the observations that countain missing data. However, before \n",
    "deleteing a column debate the importance of that column\n",
    "to your analysis. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e8066841-4859-4622-987b-10e064addaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The DataFrame has 891 rows and 15 columns.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "del df_copy['deck']\n",
    "\n",
    "del df_copy['age']\n",
    "\n",
    "df_copy.dropna(inplace=True)\n",
    "\n",
    "print(\"Missing values count\")\n",
    "print(df_copy.isnull().sum())\n",
    "\n",
    "rows_copy, columns_copy = df_copy.shape\n",
    "\n",
    "f\"The DataFrame has {rows} rows and {columns} columns.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "72829e7a-be35-41fe-a794-fba639cd0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "edbb6ee4-6033-4ed9-b995-7d0afaf2a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The DataFrame has 891 rows and 15 columns.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure we are working with the original data \n",
    "print(\"Missing values count\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "rows_copy, columns_copy = df.shape\n",
    "\n",
    "f\"The DataFrame has {rows} rows and {columns} columns.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae3d5fe1-ea37-4ec6-855d-405c1d0b5199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>child</th>\n",
       "      <td>83.0</td>\n",
       "      <td>32.785795</td>\n",
       "      <td>33.466438</td>\n",
       "      <td>7.225</td>\n",
       "      <td>15.9000</td>\n",
       "      <td>26.25</td>\n",
       "      <td>32.19375</td>\n",
       "      <td>211.3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>537.0</td>\n",
       "      <td>24.864182</td>\n",
       "      <td>44.021339</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>9.50</td>\n",
       "      <td>26.38750</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>271.0</td>\n",
       "      <td>46.570711</td>\n",
       "      <td>60.318995</td>\n",
       "      <td>6.750</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>23.25</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std    min      25%    50%       75%       max\n",
       "who                                                                          \n",
       "child   83.0  32.785795  33.466438  7.225  15.9000  26.25  32.19375  211.3375\n",
       "man    537.0  24.864182  44.021339  0.000   7.8542   9.50  26.38750  512.3292\n",
       "woman  271.0  46.570711  60.318995  6.750  10.5000  23.25  65.00000  512.3292"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  8. (1)\n",
    "# Group the data into the unique values found in column 'who'\n",
    "# Which happen to be 'man', 'woman' and 'child.\n",
    "# Do summary analysis on every individual group. \n",
    "\n",
    "# Return grouped summary analysis of 'fare' based on the \n",
    "# unique groups of column 'who'.\n",
    "df.groupby(\"who\")[\"fare\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4593058e-1ba3-4f65-be15-1a96b2ee7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. (2)\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# Note that 83.0 + 537.0 + 271.0 = 891.0 \n",
    "\n",
    "\"\"\"\n",
    "The count returned by df.groupby(\"who\")[\"fare\"].describe()\n",
    "represents the number of non-missing values returned for \n",
    "each unique group in the column \"who\". Whereas the count \n",
    "returned by df.describe() provides you the number of \n",
    "non-missing values in each column across the DataFrame.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f418a7a9-e35e-4234-b0a4-b5ccd7897d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  8. (3)\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# a)\n",
    "# The Chat bot instantly told me to import pandas as pd.\n",
    "# After copying and pasting the same error into google\n",
    "# the first was result I clicked was a stackoverflow \n",
    "# website that told me to install seaborn. \n",
    "\n",
    "# b)\n",
    "# The chatbot knew there was an issue with the path and\n",
    "# provided the right path, possibly because of our \n",
    "# previous chat. The first google result is a stackoverflow\n",
    "# site which mentions using a direct path, but can not \n",
    "# provide me the exactly url to the file. \n",
    "\n",
    "# c)\n",
    "# Chatgpt tells me that DF has not been defined or assigned a\n",
    "# DataFrame in my code and provides the code to fix it. \n",
    "# Google tells me to make sure my DataFrame is declared \n",
    "# before access. \n",
    "\n",
    "# d)\n",
    "# Chatbot tells me that I am likely missing a closing parenthesis.\n",
    "# Google told me to make sure the code lines up with the proper \n",
    "# indentation level. \n",
    "\n",
    "# e)\n",
    "# Chatgpt instantly told me the code I needed to use. \n",
    "# The first google result told me the correct function name.\n",
    "# https://www.reddit.com/r/learnpython/comments/80rrvr/pandas_attributeerror_dataframe_object_has_no/\n",
    "# Google search: AttributeError: 'DataFrame' object has no attribute 'group_by'\n",
    "\n",
    "# f)\n",
    "# Chatbot told me that the column doesn't exist, provided \n",
    "# me the code to check the columns in the DataFrame and \n",
    "# also provided me the code I was looking for. \n",
    "# It took a long time to find the problem using Gooogle. \n",
    "\n",
    "# g) Chatbot mention there was an error in my code with the \n",
    "# column name fare and provided me the code to fix it. \n",
    "# Google didn't find the exact problem. But It found similar problems.\n",
    "# Using google would have taken me alot more longer to solve. \n",
    "                 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f985e9d-76fd-4744-9ec1-df12763abf08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Who'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho\u001b[39m\u001b[38;5;124m\"\u001b[39m)[fare]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   9193\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1330\u001b[0m         obj,\n\u001b[1;32m   1331\u001b[0m         keys,\n\u001b[1;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1337\u001b[0m     )\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Who'"
     ]
    }
   ],
   "source": [
    "# df.groupby(\"Who\")[fare].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc1256-02bc-4cef-8ab5-673f30c1d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 \n",
    "# Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbe7fa-f5be-477b-b1bb-62587d7f0710",
   "metadata": {},
   "source": [
    "## Chat Log History 1 - 7 \n",
    "\n",
    "https://chatgpt.com/share/bf9a645f-9d61-49f0-879a-d06a324cd2b0\n",
    "\n",
    "## Summary \n",
    "\n",
    "### 1\n",
    "\n",
    "Summary of Exchanges\n",
    "1. Understanding DataFrame Attributes and Methods:\n",
    "\n",
    "Attributes vs. Methods:\n",
    "Attributes: Characteristics of a DataFrame that provide direct information without performing actions. For example, df.shape is an attribute that returns the dimensions (number of rows and columns) of the DataFrame.\n",
    "Methods: Functions linked to a DataFrame that perform specific operations. Methods require parentheses because they can accept arguments and execute actions or calculations. For instance, df.describe() is a method that generates summary statistics for numeric columns.\n",
    "Parentheses in Methods:\n",
    "The parentheses are used to pass additional arguments to the method, allowing it to customize its behavior. For example, df.describe(include='all') includes both numeric and non-numeric columns in the summary.\n",
    "2. Dataset Size and Summary Differences:\n",
    "\n",
    "df.shape:\n",
    "Provides the overall dimensions of the DataFrame, reporting the total number of rows and columns, including all columns regardless of type.\n",
    "df.describe():\n",
    "By default, summarizes only numeric columns, providing statistics like count, mean, and standard deviation.\n",
    "If include='all' is specified, it includes non-numeric columns and provides counts of unique values, but the 'count' row shows non-missing entries only for each column.\n",
    "3. Difference Between Mathematical Functions and Programming Functions:\n",
    "\n",
    "Mathematical Functions:\n",
    "Define static relations between inputs and outputs (e.g., f(x) = x^2).\n",
    "Programming Functions:\n",
    "Blocks of code designed to perform tasks, potentially modifying objects or interacting with other functions. Methods in programming are a type of function linked to objects that perform operations on them.\n",
    "4. Rephrased Explanation:\n",
    "\n",
    "A method is a function associated with a DataFrame object that performs operations on that DataFrame. Parentheses are necessary to accept additional arguments and customize behavior. For instance, calling .describe() uses the DataFrame as the context, while the parentheses allow for optional parameters to adjust the output.\n",
    "\n",
    "### 2\n",
    "\n",
    "Summary of Data Cleaning and Analysis Discussion:\n",
    "\n",
    "We discussed how to effectively handle missing data in a dataset using methods like df.dropna() and del df['col'] in Python with pandas. The focus was on deciding when to remove rows versus when to remove entire columns based on the importance of the data and the extent of missing values.\n",
    "\n",
    "Handling Missing Data Across Rows vs. Down Columns:\n",
    "df.dropna() removes rows or columns with missing values, which is useful when you want to preserve the structure of critical data while removing incomplete records.\n",
    "del df['col'] deletes an entire column and is useful when a column has excessive missing values or is not crucial for the analysis.\n",
    "Use Case for df.dropna():\n",
    "In a dataset of customer reviews, keeping the Sentiment_Score column intact while removing rows with missing scores ensures that valuable data for analysis is not lost, which is preferable over deleting the entire sentiment column.\n",
    "Use Case for del df['col']:\n",
    "In cases where a column, like Reviewer_Age, has a significant amount of missing data and is not essential to the analysis, removing the entire column (del df['Reviewer_Age']) can streamline the dataset and focus on more relevant data.\n",
    "Order of Operations - del Before df.dropna():\n",
    "It's important to remove columns with substantial missing values before applying df.dropna(). This prevents unnecessary loss of rows that are otherwise complete in critical columns, ensuring that the dataset retains as much valuable information as possible.\n",
    "Practical Application:\n",
    "For an example dataset, we removed a column (Reviewer_Age) with a large number of missing values using del, followed by using df.dropna() to clean the remaining rows. The \"before and after\" report showed a reduction in missing data and an efficient cleanup of the dataset, preserving important information for analysis.\n",
    "This conversation emphasized the importance of strategically handling missing data to maximize the quality and utility of a dataset in data analysis tasks.\n",
    "\n",
    "## Chat Log History 8\n",
    "\n",
    "https://chatgpt.com/share/e392948c-9b5f-4970-bd30-8a39d6744520\n",
    "\n",
    "## Summary \n",
    "\n",
    "Summary of Interactions\n",
    "1. Loading and Inspecting Data\n",
    "\n",
    "Initial Issue: You encountered a NameError indicating that pd was not defined.\n",
    "Resolution: The error was due to missing the import statement for pandas. Adding import pandas as pd resolved the issue.\n",
    "2. Handling Missing Values\n",
    "\n",
    "Task: You examined missing values in the Titanic dataset.\n",
    "Code Used: df.isnull().sum() was used to check for missing values.\n",
    "Explanation: This method returns the count of missing values for each column in the DataFrame.\n",
    "3. Understanding Data Description\n",
    "\n",
    "Question: You asked about the difference between df.describe() and df.groupby(\"col1\")[\"col2\"].describe().\n",
    "Explanation: df.describe() provides summary statistics for each column, considering missing values. df.groupby(\"col1\")[\"col2\"].describe() provides statistics for each group defined by col1, and it can handle missing values in a group-specific manner.\n",
    "4. Fixing a FileNotFoundError\n",
    "\n",
    "Issue: You encountered a FileNotFoundError because the file path was incorrect.\n",
    "Resolution: Verified the file name and path, ensuring they matched the actual file location.\n",
    "5. Correcting SyntaxError\n",
    "\n",
    "Issue: You faced a SyntaxError due to incomplete input.\n",
    "Resolution: Ensured all code statements were properly closed and complete, and verified proper syntax.\n",
    "6. Fixing AttributeError\n",
    "\n",
    "Issue: You received an AttributeError for using group_by instead of groupby.\n",
    "Resolution: Replaced group_by with groupby to correctly group the DataFrame.\n",
    "7. Fixing KeyError\n",
    "\n",
    "Issue: You encountered a KeyError due to using an incorrect column name and incorrect syntax in df.groupby(\"Who\")[fare].describe().\n",
    "Resolution: Verified the correct column name and corrected the syntax to use \"fare\" and the actual column name.\n",
    "Feel free to use this summary for your homework assignment! If you need any more details or have additional questions, just let me know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
